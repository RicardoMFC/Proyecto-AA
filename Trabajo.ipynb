{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "796b0d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas con scipy:\n",
      "  ge   cst   tnp   twp iap   esp arr         ms ls    as  ...  fq  mq  \\\n",
      "0  F     G  Good  Good  Vg  Good   Y  Unmarried  V  Paid  ...  Um  10   \n",
      "1  M   OBC    Vg    Vg  Vg    Vg   N  Unmarried  V  Paid  ...  Um  Il   \n",
      "2  F   OBC  Good  Good  Vg  Good   N  Unmarried  V  Paid  ...  12  10   \n",
      "3  M  MOBC  Pass  Good  Vg  Good   N  Unmarried  V  Paid  ...  12  Um   \n",
      "4  M     G  Good  Good  Vg    Vg   N  Unmarried  V  Paid  ...  10  12   \n",
      "\n",
      "         fo         mo       nf       sh       ss   me       tt      atd  \n",
      "0    Farmer  Housewife    Large     Poor     Govt  Asm    Small     Good  \n",
      "1   Service    Service    Small     Poor     Govt  Asm  Average  Average  \n",
      "2   Service  Housewife  Average  Average     Govt  Asm    Large     Good  \n",
      "3  Business   Business    Large     Poor     Govt  Asm  Average  Average  \n",
      "4   Service  Housewife    Large     Poor  Private  Asm    Small     Good  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Celdas para leer directamente un archivo .arff en Python\n",
    "\n",
    "# 1. Importar librerías necesarias\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "# Removed incorrect import of load_arff\n",
    "from pathlib import Path\n",
    "\n",
    "# 2. Definir la ruta al archivo .arff\n",
    "darff_path = Path('Sapfile1.arff')  # <-- Ajusta si está en otra carpeta\n",
    "\n",
    "# 3. Leer el .arff usando scipy\n",
    "#    Devuelve una tupla (data, meta)\n",
    "data_scipy, meta_scipy = arff.loadarff(str(darff_path))\n",
    "# Convertir a DataFrame\n",
    "df_scipy = pd.DataFrame(data_scipy)\n",
    "# Decodificar columnas byte a texto si es necesario\n",
    "for col in df_scipy.select_dtypes([object]):\n",
    "    df_scipy[col] = df_scipy[col].str.decode('utf-8')\n",
    "print(\"Primeras filas con scipy:\")\n",
    "print(df_scipy.head())\n",
    "\n",
    "# Removed scikit-learn related code as load_arff is not available\n",
    "\n",
    "# Opcional: mostrar información general\n",
    "\"\"\"def resumen(df):\n",
    "    print(df.info())\n",
    "    print(df.describe())\"\"\"\n",
    "\n",
    "# resumen(df_scipy)\n",
    "\n",
    "# La diferencia principal entre `df_scipy` y `data_scipy` es su tipo de datos y estructura:\n",
    "# - `data_scipy` es un numpy.ndarray que contiene los datos leídos directamente del archivo .arff.\n",
    "# - `df_scipy` es un pandas.DataFrame que se creó a partir de `data_scipy` para facilitar el análisis y manipulación de datos.\n",
    "\n",
    "# Ejemplo para verificar:\n",
    "print(type(data_scipy))  # numpy.ndarray\n",
    "print(type(df_scipy))    # pandas.DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e93a79c",
   "metadata": {},
   "source": [
    "Punto 4: Transformaciones y escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c780441f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas tras coerción con algún valor numérico: ['fq', 'mq']\n",
      "Escalado estándar OK, shape: (131, 2)\n",
      "Escalado Min-Max OK, shape: (131, 2)\n"
     ]
    }
   ],
   "source": [
    "# Punto 4: Transformaciones y escalado de variables\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# 1) Coerción: intenta convertir cada columna a float, los errores serán NaN\n",
    "df_coerced = df_scipy.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 2) Detecta las columnas que tienen ALGÚN dato numérico\n",
    "numeric_cols = [c for c in df_coerced.columns if df_coerced[c].notna().any()]\n",
    "print(\"Columnas tras coerción con algún valor numérico:\", numeric_cols)\n",
    "\n",
    "# 3) Imputa NaNs con la mediana de cada columna\n",
    "df_num = df_coerced[numeric_cols].fillna(df_coerced[numeric_cols].median())\n",
    "\n",
    "# 4) Escalado\n",
    "scaler_std = StandardScaler()\n",
    "X_std = scaler_std.fit_transform(df_num)\n",
    "print(\"Escalado estándar OK, shape:\", X_std.shape)\n",
    "\n",
    "scaler_mm = MinMaxScaler()\n",
    "X_mm = scaler_mm.fit_transform(df_num)\n",
    "print(\"Escalado Min-Max OK, shape:\", X_mm.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34be8ff",
   "metadata": {},
   "source": [
    "**asd**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b7dc32",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['class'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m df_model \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df_model, drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# --- 4) Separar X e y ---\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass_Appropriate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass_Appropriate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m y \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(df_scipy[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m], drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# ajusta según nombres de tu target\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# --- 5) Importancias con Random Forest ---\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tester\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tester\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\tester\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tester\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['class'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# --- 1) Reconstruir DataFrame con escalado estándar ---\n",
    "df_std = pd.DataFrame(X_std, columns=numeric_cols)\n",
    "\n",
    "# --- 2) Añadir variables categóricas tal cual estaban (por ejemplo 'class') ---\n",
    "cat_cols = df_scipy.select_dtypes(include=['object']).columns.tolist()\n",
    "df_model = pd.concat([df_std, df_scipy[cat_cols].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# --- 3) One-hot encoding de las categóricas ---\n",
    "df_model = pd.get_dummies(df_model, drop_first=True)\n",
    "\n",
    "# --- 4) Separar X e y ---\n",
    "X = df_model.drop('class_Appropriate' if 'class_Appropriate' in df_model.columns else 'class', axis=1)\n",
    "y = pd.get_dummies(df_scipy['class'], drop_first=True)  # ajusta según nombres de tu target\n",
    "\n",
    "# --- 5) Importancias con Random Forest ---\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X, y.values.ravel())  # si y es DataFrame, conviértelo a 1D\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "importances = importances.sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 10 features más importantes:\")\n",
    "print(importances.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f2ae3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas en df_model: ['fq', 'mq', 'ge_M', 'cst_MOBC', 'cst_OBC', 'cst_SC', 'cst_ST', 'tnp_Good', 'tnp_Pass', 'tnp_Vg', 'twp_Good', 'twp_Pass', 'twp_Vg', 'iap_Good', 'iap_Pass', 'iap_Vg', 'esp_Good', 'esp_Pass', 'esp_Vg', 'arr_Y', 'ls_V', 'as_Paid', 'fmi_High', 'fmi_Low', 'fmi_Medium', 'fmi_Vh', 'fs_Large', 'fs_Small', 'fq_12', 'fq_Degree', 'fq_Il', 'fq_Pg', 'fq_Um', 'mq_12', 'mq_Degree', 'mq_Il', 'mq_Pg', 'mq_Um', 'fo_Farmer', 'fo_Others', 'fo_Retired', 'fo_Service', 'mo_Housewife', 'mo_Others', 'mo_Retired', 'mo_Service', 'nf_Large', 'nf_Small', 'sh_Good', 'sh_Poor', 'ss_Private', 'me_Ben', 'me_Eng', 'me_Hin', 'tt_Large', 'tt_Small', 'atd_Good', 'atd_Poor']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tester\\AppData\\Local\\Temp\\ipykernel_17236\\2578226416.py\", line 7, in <module>\n",
      "    X = df_model.drop('class_Appropriate' if 'class_Appropriate' in df_model.columns else 'class', axis=1)\n",
      "  File \"c:\\Users\\tester\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py\", line 5581, in drop\n",
      "    return super().drop(\n",
      "           ~~~~~~~~~~~~^\n",
      "        labels=labels,\n",
      "        ^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "        errors=errors,\n",
      "        ^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\tester\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\", line 4788, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"c:\\Users\\tester\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\", line 4830, in _drop_axis\n",
      "    new_axis = axis.drop(labels, errors=errors)\n",
      "  File \"c:\\Users\\tester\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 7070, in drop\n",
      "    raise KeyError(f\"{labels[mask].tolist()} not found in axis\")\n",
      "KeyError: \"['class'] not found in axis\"\n"
     ]
    }
   ],
   "source": [
    "# 1) Muestra las columnas de df_model\n",
    "print(\"Columnas en df_model:\", df_model.columns.tolist())\n",
    "\n",
    "# 2) Intenta separar X e y y captura el error\n",
    "try:\n",
    "    # Ajusta aquí 'class' por el nombre de tu target si difiere\n",
    "    X = df_model.drop('class_Appropriate' if 'class_Appropriate' in df_model.columns else 'class', axis=1)\n",
    "    y = pd.get_dummies(df_scipy['class'], drop_first=True) \n",
    "    print(\"Separación OK\")\n",
    "except Exception as e:\n",
    "    import traceback; traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
